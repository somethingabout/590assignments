{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.giphy.com/media/Ldepo9xvqWDYI/giphy.gif)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You must pick data that you would like to collect for web-scraping - the data **MUST** come from APIs (none of this download csv stuff). The data set will be your final project. You can ammend and make changes later to data sources and variables. Get creative!\n",
    "\n",
    "Be mindful of the timeline - ambitious project can't be completed in 2 months, but a snapshot of it can be done. \n",
    "\n",
    "You must pick one variable that does not exist yet or is not obviously common. The variable should either be web-scraped or if it is from an API, it must be calculated (and not very common). For example, songs per capita is commmon - you might have to calculate it, but it doesn't count. Genre concentration by state is a variable that is acceptable. Remember only **ONE** variable has to be calculated/webscraped, but you will need a total of 3 variables.\n",
    "\n",
    "In the final project, you will be providing your code and documentation (not this assignment). I will test the code you give me to make sure it runs.\n",
    "\n",
    "For my sanity - format the proposal to be organized. Include graphs, photos, examples, etc. But, please make it look professional and clean. The easier it is to read, the easier it is for me to grade, and better outcomes will likely follow.\n",
    "\n",
    "This is a proposal, so you do not have to collect the data now.\n",
    "\n",
    "In your proposal you must include:\n",
    "1. Identify the website/API that you will be web-scraping data from. You can also suggest a variety of websites via web crawling (for example, if you want to crawl websites of selected non-profit organizations and collect information about the board members - this is doable.) Go outside your comfort zone - if you've worked with APIs, then do webscraping.\n",
    "\n",
    "2. Define at least 3 variables that you will be collecting via API or webscraping. You may combine these webscraped or API collected data with other sources, but MUST cite those other datasources. You can collect data completely internally.\n",
    "\n",
    "3. If it is an open access API, get an authorization key (if neccessary), if it is not needed, also note that. Provide evidence of this with screen shot that you obtained said key or a link (and a summary in your proposal) of the documentation that says it's freely accessible.\n",
    "\n",
    "4. If it is not an open access API, ensure that you meet the terms and conditions (there is wiggle room here - but, if you are trying to crack a google related non-open access API, that's unreasonable and not possible in this class. However, if it is a Google/Amazon/InsertBigTechComp with open access API - that is do-able!). Most websites have terms and conditions, include a link to this information and briefly (a few sentences) describe what you can or can't get access to.\n",
    "\n",
    "5. Identify your research question - what are you going to analyze? Remember that after getting the data, you will make meaningful graphs and run regressions with it. \n",
    "\n",
    "6. Give me a bit of background and motivation. Why are you scraping this data? Why should you research/study this question?  This should not be personal motivation, but motivated academically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
